{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Drving: Vehicle Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enviroment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "\n",
    "from skimage.feature import hog\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "VEHICLE_DIR = \"./train/vehicles/\"\n",
    "NON_VEHICLE_DIR = \"./train/non-vehicles/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(image, color_space='RGB', size=(32, 32)):\n",
    "    # Convert image to new color space (if specified)\n",
    "    color_space_dict = {\"HSV\": cv2.COLOR_RGB2HSV, \"HLS\": cv2.COLOR_RGB2HLS, \"YCrCb\" :cv2.COLOR_RGB2YCrCb}\n",
    "    \n",
    "    img = cv2.resize(image, size)\n",
    "    if color_space in color_space_dict.keys():\n",
    "        image = cv2.cvtColor(image, color_space_dict[color_space])\n",
    "    \n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = image.ravel() # Remove this line!\n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "def extract_features(image_path_list, color_channel, orientations, pix_per_cell, cell_per_block):\n",
    "    COLOR_CHANNEL_DICT = {\"HLS:S\": (cv2.COLOR_RGB2HLS, 2), \"YCrCb:Y\": (cv2.COLOR_RGB2YCrCb, 0), \"YCrCb:Cr\": (cv2.COLOR_RGB2YCrCb, 1)}\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for image_path in image_path_list:\n",
    "        image = read_image(image_path)\n",
    "    \n",
    "        if  color_channel in COLOR_CHANNEL_DICT.keys():\n",
    "            image = cv2.cvtColor(image, COLOR_CHANNEL_DICT[color_channel][0])[:,:,COLOR_CHANNEL_DICT[color_channel][1]]\n",
    "        else:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "        hog_features = get_hog_features(image, orientations, pix_per_cell, cell_per_block,  vis=False, feature_vec=True)\n",
    "        features.append(hog_features)\n",
    "    \n",
    "    return features\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_image_path_list = glob.glob(VEHICLE_DIR + \"./*/*.png\")\n",
    "non_vehicle_image_path_list = glob.glob(NON_VEHICLE_DIR + \"./*/*.png\")\n",
    "\n",
    "print(\"vehicle image count: \" + str(len(vehicle_image_path_list)) + \" non vehicle image count: \" + str(len(non_vehicle_image_path_list)))\n",
    "\n",
    "#example output\n",
    "for i in range(3):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    f.tight_layout()\n",
    "    vehicle_image = read_image(random.choice(vehicle_image_path_list))\n",
    "    non_vehicle_image = read_image(random.choice(non_vehicle_image_path_list))\n",
    "    ax1.imshow(vehicle_image)\n",
    "    ax1.set_title(\"vehicle \" + str(vehicle_image.shape))\n",
    "    ax2.imshow(non_vehicle_image)\n",
    "    ax2.set_title(\"non vehicle \" + str(non_vehicle_image.shape))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of Oriented Gradients (HOG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracted HOG Features from the Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_CHANNEL_DICT = {\"HLS:S\": (cv2.COLOR_RGB2HLS, 2), \"YCrCb:Y\": (cv2.COLOR_RGB2YCrCb, 0), \"YCrCb:Cr\": (cv2.COLOR_RGB2YCrCb, 1)}\n",
    "\n",
    "orientations = [8, 9]\n",
    "pixels_per_cell = [6, 8]\n",
    "cells_per_block = [2, 3]\n",
    "\n",
    "parameter_combination_list = list(itertools.product(orientations, pixels_per_cell, cells_per_block))\n",
    "\n",
    "car_image_path = random.choice(vehicle_image_path_list)\n",
    "not_car_image_path = random.choice(non_vehicle_image_path_list)\n",
    "\n",
    "for color_channel in COLOR_CHANNEL_DICT.keys():\n",
    "    print(color_channel)\n",
    "    car_image = read_image(car_image_path)\n",
    "    not_car_image = read_image(not_car_image_path)\n",
    "    \n",
    "    color_space = COLOR_CHANNEL_DICT[color_channel][0]\n",
    "    color_channel_index = COLOR_CHANNEL_DICT[color_channel][1] \n",
    "    \n",
    "    car_image = cv2.cvtColor(car_image,color_space)[:,:,color_channel_index]\n",
    "    not_car_image = cv2.cvtColor(not_car_image, color_space)[:,:,color_channel_index]\n",
    "    \n",
    "    for parameter_combination in parameter_combination_list: \n",
    "        car_features, car_hog_image = get_hog_features(car_image, parameter_combination[0], parameter_combination[1], parameter_combination[2], \n",
    "                        vis=True, feature_vec=True)\n",
    "        \n",
    "        not_car_features, not_car_hog_image = get_hog_features(not_car_image, parameter_combination[0], parameter_combination[1], parameter_combination[2], \n",
    "                        vis=True, feature_vec=True)\n",
    "        \n",
    "        f, axes = plt.subplots(1, 4, figsize=(16, 8))\n",
    "        \n",
    "        axes = axes.ravel()\n",
    "        axes[0].imshow(car_image,cmap='gray')\n",
    "        axes[0].set_title(\"car in \" + color_channel)\n",
    "        \n",
    "        axes[1].imshow(car_hog_image,cmap='gray')\n",
    "        axes[1].set_title(\"car HOG \\n (orientations,pixels_per_cell, cells_per_block) = \\n\" + str(parameter_combination))\n",
    "        \n",
    "        axes[2].imshow(not_car_image, cmap='gray')\n",
    "        axes[2].set_title(\"not car in \" + color_channel)\n",
    "        \n",
    "        axes[3].imshow(not_car_hog_image,cmap='gray')\n",
    "        axes[3].set_title(\"not car HOG\\n (orientations,pixels_per_cell, cells_per_block) = \\n\" + str(parameter_combination))\n",
    "        \n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classfier Trainning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_features = extract_features(vehicle_image_path_list, \"YCrCb:Y\", orientations = 8, pix_per_cell = 8, cell_per_block = 2)\n",
    "non_vehicle_features = extract_features(non_vehicle_image_path_list, \"YCrCb:Y\", orientations = 8, pix_per_cell = 8, cell_per_block = 2)\n",
    "\n",
    "print(\"vehicle image count: \" + str(len(vehicle_features)) + \" , non vehicle image count: \" + str(len(non_vehicle_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
